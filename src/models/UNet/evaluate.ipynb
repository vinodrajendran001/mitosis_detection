{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2 \n",
    "from PIL import Image\n",
    "from unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (down_conv_1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (down_conv_2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (down_conv_3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (down_conv_4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (down_conv_5): Sequential(\n",
       "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (up_conv_trans_1): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (up_conv_trans_2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (up_conv_trans_3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (up_conv_trans_4): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (up_conv_1): Sequential(\n",
       "    (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (up_conv_2): Sequential(\n",
       "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (up_conv_3): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (up_conv_4): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_1x1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_load = \"/home/vinod/Documents/mitosis_detection/models/UNet/checkpoint_epoch100.pth\"\n",
    "model = UNet(in_chnls = 3, n_classes = 1)\n",
    "model.load_state_dict(torch.load(model_load))\n",
    "model.to(device=device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/data1/vinod/mitosis/data/processed/val/input/A00_02.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(img_path)\n",
    "\n",
    "test_transform = A.Compose([A.Resize(512,512),\n",
    "                        A.Normalize(mean=(0,0,0),std=(1,1,1),max_pixel_value=255),\n",
    "                        ToTensorV2()])\n",
    "\n",
    "test_image = test_transform(image = np.asarray(img))\n",
    "test_image = test_image[\"image\"].unsqueeze(0)\n",
    "test_image = test_image.to(device)\n",
    "\n",
    "mask_path = img_path.replace(\"input\",\"output\")\n",
    "mask = Image.open(mask_path)\n",
    "mask = mask.resize((512, 512))\n",
    "test_mask = np.copy(np.asarray(mask))\n",
    "test_mask[test_mask==255] = 1\n",
    "\n",
    "pred_mask = model(test_image)\n",
    "pred_mask = pred_mask.squeeze(0).cpu().detach().numpy()\n",
    "pred_mask = pred_mask.transpose(1,2,0)\n",
    "pred_mask[pred_mask < 0]=0\n",
    "pred_mask[pred_mask > 0]=1\n",
    "pred_mask = np.squeeze(pred_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(pred_mask, target_mask):\n",
    "    # Flatten the masks\n",
    "    pred_mask = pred_mask.flatten()\n",
    "    target_mask = target_mask.flatten()\n",
    "\n",
    "    # Calculate intersection and union\n",
    "    intersection = np.logical_and(pred_mask, target_mask)\n",
    "    union = np.logical_or(pred_mask, target_mask)\n",
    "\n",
    "    # Compute IOU score\n",
    "    iou = np.sum(intersection) / np.sum(union)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU score: 0.2786885245901639\n"
     ]
    }
   ],
   "source": [
    "iou_score = compute_iou(pred_mask, test_mask)\n",
    "print(\"IOU score:\", iou_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pixel_accuracy(pred_mask, target_mask):\n",
    "    # Flatten the masks\n",
    "    pred_mask = pred_mask.flatten()\n",
    "    target_mask = target_mask.flatten()\n",
    "\n",
    "    # Calculate pixel accuracy\n",
    "    pixel_accuracy = np.mean(pred_mask == target_mask)\n",
    "\n",
    "    return pixel_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average IOU score: 0.23698373026450534\n",
      "Average pixel accuracy: 0.9986399600380346\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder containing predicted and target masks\n",
    "folder_path = '/data1/vinod/mitosis/data/processed/val/input'\n",
    "\n",
    "iou_scores = []\n",
    "pixel_accuracies = []\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.png'):\n",
    "        # Load predicted and target masks\n",
    "        img_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        test_transform = A.Compose([A.Resize(512,512),\n",
    "                                A.Normalize(mean=(0,0,0),std=(1,1,1),max_pixel_value=255),\n",
    "                                ToTensorV2()])\n",
    "\n",
    "        test_image = test_transform(image = np.asarray(img))\n",
    "        test_image = test_image[\"image\"].unsqueeze(0)\n",
    "        test_image = test_image.to(device)\n",
    "\n",
    "        mask_path = img_path.replace(\"input\",\"output\")\n",
    "        mask = Image.open(mask_path)\n",
    "        mask = mask.resize((512, 512))\n",
    "        test_mask = np.copy(np.asarray(mask))\n",
    "        test_mask[test_mask==255] = 1\n",
    "\n",
    "        pred_mask = model(test_image)\n",
    "        pred_mask = pred_mask.squeeze(0).cpu().detach().numpy()\n",
    "        pred_mask = pred_mask.transpose(1,2,0)\n",
    "        pred_mask[pred_mask < 0]=0\n",
    "        pred_mask[pred_mask > 0]=1\n",
    "        pred_mask = np.squeeze(pred_mask)\n",
    "\n",
    "        # Compute IOU score for the current image\n",
    "        iou_score = compute_iou(pred_mask, test_mask)\n",
    "        iou_scores.append(iou_score)\n",
    "        # Compute pixel accuracy for the current image\n",
    "        pixel_accuracy = compute_pixel_accuracy(pred_mask, test_mask)\n",
    "        pixel_accuracies.append(pixel_accuracy)\n",
    "\n",
    "# Compute average IOU score\n",
    "avg_iou_score = np.mean(iou_scores)\n",
    "print(\"Average IOU score:\", avg_iou_score)\n",
    "# Compute average pixel accuracy\n",
    "avg_pixel_accuracy = np.mean(pixel_accuracies)\n",
    "print(\"Average pixel accuracy:\", avg_pixel_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
